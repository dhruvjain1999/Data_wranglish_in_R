---
title: "web_scraping"
author: "Dhruv"
date: "2023-05-12"
output: html_document
---



```{r}
library(rvest)
library(tidyverse)
library(repurrrsive)
library(listviewer)
#listviewer::jsonedit(gh_users)
library(conflicted)
library(data.table)
library(textdata)
library(tidytext)
library(tm)
library(SnowballC)
library(wordcloud)
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(conflicted)
library(data.table)
library(dbplyr)
library(dplyr)
library(ggforce)
library(ggmap)
library(ggmosaic)
library(ggplot2)
library(ggthemes)
library(gridExtra)
library(keep)
library(listviewer)
library(MASS)
library(mapview)
library(Matrix)
library(olsrr)
library(purrr)
library(plotly)
library(readr)
library(repurrrsive)
library(rnaturalearth)
library(rnaturalearthdata)
library(RColorBrewer)
library(rvest)
library(sf)
library(SnowballC)
library(textdata)
library(tibble)
library(tidytext)
library(tidyverse)
library(tm)
library(wordcloud)
library(usmap)
library(leaflet)
library(viridis)


```

```{r}
Link <- "https://www.cnn.com/politics"
page = read_html(Link)

DayNight = page%>% 
  html_nodes(".container_lead-plus-headlines__headline span")%>%
  html_text()


news = data.frame(DayNight)
news



# Link <- "https://www.american.edu/magazine/inside-beltway/"
# page = read_html(Link)
# 
# DayNight = page%>% 
#   html_nodes(".teaser , #CS_Element_maincontainer h1")%>%
#   html_text()
# 
# 
# 
# news = data.frame(DayNight)
# news
# 
# 


```





```{r}
docs <- Corpus(VectorSource(news))
#docs

inspect(docs)


toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
toSpace
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")


# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("blabla1", "blabla2")) 
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
docs <- tm_map(docs, stemDocument)

# Now organize words and frequences in a table

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 2000)


# Now code to create the Word Cloud

set.seed(1234567)
wordcloud2(data = d, size = 1.5, minSize = 0.5, gridSize = 2, 
           fontFamily = "sans-serif", fontWeight = "bold",
           color = "random-light", backgroundColor = "white",
           shuffle = FALSE, rotateRatio = 0.15,
           shape = "star", ellipticity = 0.65, widgetsize = NULL,
           figPath = NULL)

```
